{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from scipy import misc\n",
    "from imutils import paths\n",
    "from Detection import Detection\n",
    "from Recognition import Recognition\n",
    "import align_dataset\n",
    "import preprocess\n",
    "import pandas as pd\n",
    "import gen_classifier\n",
    "import classify_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input and Output paths\n",
    "train_raw_path = \"/home/santoshv/RT_facenet/Dataset/train_raw/\"\n",
    "train_aligned_path = \"/home/santoshv/RT_facenet/Dataset/train_aligned/\"\n",
    "output_classifier_path = \"/home/santoshv/RT_facenet/util/classifier.pkl\"\n",
    "test_image_input_path = \"/home/santoshv/facenet/data/images/test_raw/ravikiran/Capture+_2019-02-19-16-37-01.png\"\n",
    "augmentation = False\n",
    "#Not yet Implemented.\n",
    "if augmentation == True:\n",
    "    augmentation_folder_path = \"/home/santoshv/RT_facenet/Dataset/augmentation_folder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the detection and recognition pb files\n",
    "Detection_model_path = \"/home/santoshv/RT_facenet/Models/Detection_mtcnn.pb\"\n",
    "Recognition_model_path = \"/home/santoshv/RT_facenet/Models/Recognition_facenet.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Model Graph Initialized\n",
      "Recognition Model Graph Initialized\n"
     ]
    }
   ],
   "source": [
    "#Instances of detection and recognition are being created.\n",
    "#Instances are created to avoid loading the graphs and sessions again and again for every frame.\n",
    "detection = Detection(Detection_model_path)\n",
    "recognition = Recognition(Recognition_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the identity directories inside the output folder\n",
    "#cropping faces using MTCNN face detection model from the model path \n",
    "#writing the respective faces in the directories created\n",
    "#this function needs the paths of raw training images folder, output aligned folder and detection model path\n",
    "#We suggest to manually remove noise from the aligned folder as MTCNN can detect some false positives which will\n",
    "#effect recognition performance.Making sure we send right data to the model will leave us with good accuracy.\n",
    "align_dataset.align_data(train_raw_path,train_aligned_path,Detection_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the features of the faces stored at train_aligned_path in the form of 512-D embeddings\n",
    "#We are using the FaceNet Inception-Resnet architecture to generate the embeddings which uses softmax loss\n",
    "#The model is not the same that was mentioned in facenet paper, as it has different neural structure and loss\n",
    "#Generated embeddings and the labels are given to a support vector classfier \n",
    "#The trained model is stored in the file path given to the function\n",
    "gen_classifier.rec_gen_classifier(train_aligned_path , recognition ,output_classifier_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_input_path = \"/home/santoshv/facenet/data/images/test_raw/ravikiran/Capture+_2019-02-19-16-37-01.png\"\n",
    "with open(output_classifier_path, 'rb') as infile:\n",
    "    model = pickle.load(infile)\n",
    "image = cv2.imread(test_image_input_path)\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "bbox, scores, landmarks = detection.detect(rgb_image)\n",
    "for box in bbox:\n",
    "    box = box.astype('int32')\n",
    "    face = np.copy(rgb_image[box[0]:box[2] , box[1]:box[3]])\n",
    "    processed_face = preprocess.prewhiten(face)\n",
    "    emb = recognition.recognize(processed_face)\n",
    "    predictions_proba = model.predict_proba(emb)\n",
    "    predicted_name = model.predict(emb)\n",
    "    print(predicted_name, \"   \", predictions_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_image.classify_image(output_classifier_path , detection , recognition ,test_image_input_path )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

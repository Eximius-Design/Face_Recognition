{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tfs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from scipy import misc\n",
    "from Detection import Detection\n",
    "from Recognition import Recognition\n",
    "from Smoothen_recog import Smoothen_recog\n",
    "import preprocess\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for reading the video\n",
    "Input_video_path = \"../../Dataset/EximiusAI_Dataset/Original/Videos/20190312_153102.mp4\"\n",
    "Output_video_path = \"../Outputs/Detection_Recognition_outputs/\"\n",
    "Output_video_name = \"EximiusAI_12.avi\"\n",
    "classifier_pickle_file = \"../util/classifier_sgd_casia.pkl\"\n",
    "O_path = Output_video_path + Output_video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the detection and recognition pb files\n",
    "Detection_model_path = \"../Models/Detection_mtcnn.pb\"\n",
    "Recognition_model_path = \"../Models/Recognition_facenet.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instances of detection and recognition are being created.\n",
    "#Instances are created to avoid loading the graphs and sessions again and again for every frame.\n",
    "detection = Detection(Detection_model_path)\n",
    "recognition = Smoothen_recog(Recognition_model_path , classifier_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(Input_video_path)\n",
    "#Variable to count frames.\n",
    "frame_count = 0\n",
    "#starting the processing time to calculate fps.\n",
    "start = time.time()\n",
    "#Ensuring the input_video_path opens without errors.\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "#getting the frame_width , frame_height from the given input video.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frame_area = frame_width * frame_height\n",
    "\n",
    "#Change Orientation\n",
    "temp = frame_height\n",
    "frame_height = frame_width\n",
    "frame_width = temp\n",
    "\n",
    "out = cv2.VideoWriter(O_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30 , (frame_width,frame_height))\n",
    "\n",
    "#Reading each and every frame in a while loop and processing/inferencing them through two models.\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    frame_start_time = time.time()\n",
    "    frame_count = frame_count+1\n",
    "    if ret != True or frame_count>10000:\n",
    "        break\n",
    "    if ret == True:\n",
    "        frame = imutils.rotate_bound(frame,90)\n",
    "        #Inferencing the Detection model\n",
    "        bbox, scores, landmarks = detection.detect(frame)\n",
    "        \n",
    "        if len(bbox) != 1:\n",
    "            _ = recognition.recog(len(bbox), 0)\n",
    "        \n",
    "        if len(bbox) == 1:\n",
    "            box = bbox[0]\n",
    "            box = box.astype('int32')\n",
    "            box_w = box[3] - box[1]\n",
    "            box_h = box[2] - box[0]\n",
    "            box_a = box_w*box_h\n",
    "            percent = box_a*100/frame_area\n",
    "\n",
    "            # CROPPING THE FACES OUT OF THE IMAGE AND APPENDING THEM TO THE LIST\n",
    "            print('[INFO] percentage of bounding box in total image : {:.2f}'.format(percent))\n",
    "            face = np.copy(frame[box[0]:box[2] , box[1]:box[3]])\n",
    "            if percent >1.0 and face.shape[0] != 0 and face.shape[1]!= 0 and face.shape[2] !=0:\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "                face = preprocess.prewhiten(face)\n",
    "                prediction_id, best_class_probabilities = recognition.recog(1,face)\n",
    "                prob_color_g = int(best_class_probabilities*255)\n",
    "                prob_color_r = 255 - prob_color_g\n",
    "                tup = (0,prob_color_g,prob_color_r)\n",
    "                if best_class_probabilities < 0.5:\n",
    "                    prediction_id = [\"Unknown\"]\n",
    "                    conf = \"-\"\n",
    "                print(\"Prediction ID:\",str(prediction_id[0]))\n",
    "                frame = cv2.rectangle(frame, (box[1], box[0]), (box[3], box[2]), tup, 3)\n",
    "                cv2.putText(frame, prediction_id[0], (box[1], box[0]),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, tup ,\n",
    "                            thickness=2, lineType=2)\n",
    "        out.write(frame)\n",
    "        \n",
    "        frame_end_time = time.time()\n",
    "        time_per_frame = frame_end_time - frame_start_time\n",
    "        fps_frame = 1/time_per_frame\n",
    "        print('[INFO] total boxes:', len(bbox))\n",
    "        print('[INFO] Processing Frame:', frame_count)\n",
    "        print('[INFO] Processing Speed:',fps_frame,\" FPS\")\n",
    "        print('[INFO] Time Per Frame:', time_per_frame)\n",
    "        \n",
    "end = time.time()\n",
    "timet = end - start\n",
    "fps = frame_count/timet\n",
    "print(\"[INFO] NUMBER OF FRAMES:\", frame_count)\n",
    "print(\"[INFO] Detection took {:.5} seconds\".format(end - start))\n",
    "print(\"[INFO] Overall FPS: \"+ str(fps))\n",
    "\n",
    "# closing the writer and reader\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

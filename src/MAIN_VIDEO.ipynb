{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from scipy import misc\n",
    "from Detection import Detection\n",
    "from Recognition import Recognition\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for reading the video\n",
    "Input_video_path = \"/home/santoshv/RT_facenet/Dataset/videos/vid1.mp4\"\n",
    "Output_video_path = \"/home/santoshv/RT_facenet/Outputs/Detection_Recognition_outputs/\"\n",
    "Output_video_name = \"Detection_Recognition.avi\"\n",
    "classifier_pickle_file = \"/home/santoshv/RT_facenet/util/classifier.pkl\"\n",
    "O_path = Output_video_path + Output_video_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for the detection and recognition pb files\n",
    "Detection_model_path = \"/home/santoshv/RT_facenet/Models/Detection_mtcnn.pb\"\n",
    "Recognition_model_path = \"/home/santoshv/RT_facenet/Models/Recognition_facenet.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Model Graph Initialized\n",
      "Recognition Model Graph Initialized\n"
     ]
    }
   ],
   "source": [
    "#Instances of detection and recognition are being created.\n",
    "#Instances are created to avoid loading the graphs and sessions again and again for every frame.\n",
    "detection = Detection(Detection_model_path)\n",
    "recognition = Recognition(Recognition_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(classifier_pickle_file, 'rb') as infile:\n",
    "    (model) = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] percentage of bounding box in total image : 2.66\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c4c7664290f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m#                 print(\"BEST CLASS PROBABILITIES\", best_class_probabilities)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_class_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%4d  %s: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_class_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_class_probabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "#Initializing video capture from the Input_video_path.\n",
    "cap = cv2.VideoCapture(Input_video_path)\n",
    "#Variable to count frames.\n",
    "frame_count = 0\n",
    "#starting the processing time to calculate fps.\n",
    "start = time.time()\n",
    "#Ensuring the input_video_path opens without errors.\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "#getting the frame_width , frame_height from the given input video.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "frame_area = frame_width * frame_height\n",
    "\n",
    "#creating a video file to write the output frames at output_video_path(O_path).\n",
    "\n",
    "out = cv2.VideoWriter(O_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30 , (frame_width,frame_height))\n",
    "\n",
    "#Reading each and every frame in a while loop and processing/inferencing them through two models.\n",
    "grab = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    frame_start_time = time.time()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_count = frame_count+1\n",
    "    if ret != True or frame_count>1000:\n",
    "        break\n",
    "    if ret == True:\n",
    "        \n",
    "        #Detection Starts :\n",
    "        \n",
    "        #Inferencing the Detection model\n",
    "        bbox, scores, landmarks = detection.detect(frame)\n",
    "        for box, pts in zip(bbox, landmarks):\n",
    "            box = box.astype('int32')\n",
    "            box_w = box[3] - box[1]\n",
    "            box_h = box[2] - box[0]\n",
    "            box_a = box_w*box_h\n",
    "            percent = box_a*100/frame_area\n",
    "            \n",
    "            # CROPPING THE FACES OUT OF THE IMAGE AND APPENDING THEM TO THE LIST\n",
    "            print('[INFO] percentage of bounding box in total image : {:.2f}'.format(percent))\n",
    "            face = np.copy(frame[box[0]:box[2] , box[1]:box[3]])\n",
    "            if percent >1.0 and face.shape[0] != 0 and face.shape[1]!= 0 and face.shape[2] !=0:\n",
    "                if grab == 0:\n",
    "                    img = face\n",
    "                grab = grab+1\n",
    "#                 plt.imshow(face)\n",
    "#                 plt.show()\n",
    "                face = preprocess.prewhiten(face)\n",
    "#                 print(face.shape)\n",
    "                embedding = recognition.recognize(face = face)\n",
    "                predictions = model.predict_proba(embedding)\n",
    "#                 print(\"PREDICTIONS :\",predictions)\n",
    "                best_class_indices = np.argmax(predictions, axis=1)\n",
    "#                 print(\"BEST CLASS INDICES\", best_class_indices)\n",
    "                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "#                 print(\"BEST CLASS PROBABILITIES\", best_class_probabilities)\n",
    "#                 for i in range(len(best_class_indices)):\n",
    "#                     print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n",
    "                frame = cv2.rectangle(frame, (box[1], box[0]), (box[3], box[2]), (255, 0, 0), 3)\n",
    "                pts = pts.astype('int32')\n",
    "                \n",
    "                class_prob = class_names[best_class_indices[i]]+\" : {:.2f}\".format(best_class_probabilities[i])\n",
    "                cv2.putText(frame, class_prob, (box[1], box[0]),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0),\n",
    "                            thickness=2, lineType=2)\n",
    "                #Uncomment this to have landmarks\n",
    "#                 for i in range(5):\n",
    "#                     frame = cv2.circle(frame, (pts[i+5], pts[i]), 4, (0, 0, 255), 8)\n",
    "                \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        #Writing to the video output\n",
    "        out.write(frame)\n",
    "        \n",
    "        frame_end_time = time.time()\n",
    "        time_per_frame = frame_end_time - frame_start_time\n",
    "        fps_frame = 1/time_per_frame\n",
    "        print('[INFO] total boxes:', len(bbox))\n",
    "        print('[INFO] Processing Frame:', frame_count)\n",
    "        print('[INFO] Processing Speed:',fps_frame,\" FPS\")\n",
    "        print('[INFO] Time Per Frame:', time_per_frame)\n",
    "        \n",
    "end = time.time()\n",
    "timet = end - start\n",
    "fps = frame_count/timet\n",
    "print(\"[INFO] NUMBER OF FRAMES:\", frame_count)\n",
    "print(\"[INFO] Detection took {:.5} seconds\".format(end - start))\n",
    "print(\"[INFO] Overall FPS: \"+ str(fps))\n",
    "\n",
    "# closing the writer and reader\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
